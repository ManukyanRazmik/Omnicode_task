{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c446ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import ShakespeareDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d537fbc1-8556-4f01-b8af-12e563c25e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 10\n",
    "learning_rate = 5e-4\n",
    "model_path = './tuned_model'\n",
    "tokenizer_path ='./tokenizer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84bd4f67-dd2b-41ef-aa8e-b4de3caf8ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6438347-4dbe-4da2-b0cc-4f95928057ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70e92222",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = ShakespeareDataset(path='data/Shakespeare_data.csv',  col = 'PlayerLine', tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c04a5f8a-3d81-4b33-93b9-463c7806f713",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(my_dataset, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669e64bf-2907-45d8-8bec-01ddad242e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d3a43a-2b92-483b-b1d3-999ffbac2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:        \n",
    "        input_ids  = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = input_ids.clone()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask = attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "       \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{epoch}, Average Loss: {average_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_data:\n",
    "            input_ids_val = batch['input_ids']\n",
    "            attention_mask_val = batch['attention_mask']\n",
    "            labels_val = input_ids_val.clone()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs_val = model(input_ids=input_ids_val, attention_mask=attention_mask_val, labels=labels_val)\n",
    "            val_loss = outputs_val.loss\n",
    "\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    average_val_loss = total_val_loss / len(val_data)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Validation Average Loss: {average_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b0ea7-7741-4212-9d6b-2366dcc4558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(tokenizer_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_mess",
   "language": "python",
   "name": "venv_mess"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
